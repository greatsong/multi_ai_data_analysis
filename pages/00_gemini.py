import streamlit as st
import pandas as pd
import google.generativeai as genai

# --- í˜ì´ì§€ ì„¤ì • ë° ê¸°ë³¸ ìŠ¤íƒ€ì¼ ---
st.set_page_config(
    page_title="ë°ì´í„° ë¶„ì„ ì½”ë“œ ìƒì„±ê¸°",
    page_icon="ğŸ“Š",
    layout="wide"
)

# Gemini API í‚¤ ì„¤ì •
# Streamlit Cloudì˜ Secretsì—ì„œ API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    GEMINI_API_AVAILABLE = True
except (KeyError, AttributeError):
    st.error("âš ï¸ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .streamlit/secrets.toml íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    GEMINI_API_AVAILABLE = False

# --- í•¨ìˆ˜ ì •ì˜ ---

def load_data(uploaded_file):
    """ì—…ë¡œë“œëœ íŒŒì¼ì„ pandas DataFrameìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
        elif uploaded_file.name.endswith(('.xls', '.xlsx')):
            df = pd.read_excel(uploaded_file)
        else:
            st.warning("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. CSV ë˜ëŠ” Excel íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            return None
        return df
    except Exception as e:
        st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

def get_gemini_response(user_prompt, df_info):
    """Gemini APIì— ìš”ì²­ì„ ë³´ë‚´ê³  ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë°›ìŠµë‹ˆë‹¤."""
    model = genai.GenerativeModel('gemini-1.5-pro-latest')
    
    # Geminiì—ê²Œ ì „ë‹¬í•  ì‹œìŠ¤í…œ ëª…ë ¹ì–´ (ì—­í•  ë¶€ì—¬)
    system_instruction = f"""
    ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì´ë©°, Streamlit ì½”ë“œë¥¼ ìƒì„±í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
    ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì‚¬ìš©ìì˜ í•œê¸€ ìš”ì²­ê³¼ ì œê³µëœ ë°ì´í„°í”„ë ˆì„ì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, Streamlitì—ì„œ ë°”ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ Python ì½”ë“œë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

    **ê·œì¹™:**
    1.  ë°ì´í„°ëŠ” ì´ë¯¸ `df`ë¼ëŠ” ì´ë¦„ì˜ pandas DataFrameìœ¼ë¡œ ë¡œë“œë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•˜ì„¸ìš”. (ë°ì´í„° ë¡œë”© ì½”ë“œëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.)
    2.  `import streamlit as st`ì™€ `import pandas as pd`ëŠ” ì´ë¯¸ ì„ ì–¸ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•˜ì„¸ìš”.
    3.  ì˜¤ì§ ìš”ì²­ëœ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” Streamlit ì½”ë“œ ë¸”ë¡ë§Œ ìƒì„±í•˜ì„¸ìš”. ì½”ë“œ ì™¸ì˜ ì„¤ëª…ì´ë‚˜ ì£¼ì„ì€ ìµœì†Œí™”í•˜ê³ , ì½”ë“œ ë¸”ë¡ìœ¼ë¡œ ê°ì‹¸ì„œ ì œê³µí•˜ì„¸ìš”.
    4.  ë°ì´í„° ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•˜ë‹¤ë©´, `plotly.express` ë˜ëŠ” `matplotlib.pyplot` ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
    5.  ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê³  ì§ê´€ì ì¸ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
    
    **ì œê³µëœ ë°ì´í„°í”„ë ˆì„ ì •ë³´:**
    {df_info}
    """
    
    # ëª¨ë¸ì— í”„ë¡¬í”„íŠ¸ ì „ë‹¬
    response = model.generate_content(
        [system_instruction, user_prompt],
        stream=True
    )
    return response

# --- ë©”ì¸ ì•± êµ¬ì„± ---

st.title("ğŸ“Š AI ë°ì´í„° ë¶„ì„ ì½”ë“œ ìƒì„± ë„ìš°ë¯¸")
st.markdown("---")

# ì‚¬ì´ë“œë°” êµ¬ì„±
with st.sidebar:
    st.header("1. ë°ì´í„° ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("CSV ë˜ëŠ” Excel íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["csv", "xls", "xlsx"])
    
    if uploaded_file:
        st.success(f"'{uploaded_file.name}' íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    st.markdown("---")
    st.header("ğŸ’¡ êµìœ¡ì  ê¸°ëŠ¥")
    
    # êµìœ¡ì  ê¸°ëŠ¥ 1: ì½”ë“œ ì„¤ëª… ê¸°ëŠ¥
    explain_code = st.toggle("ìƒì„±ëœ ì½”ë“œ ì„¤ëª… ë³´ê¸°")
    
    # êµìœ¡ì  ê¸°ëŠ¥ 2: ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ
    suggest_next = st.toggle("ë‹¤ìŒ ë¶„ì„ ë‹¨ê³„ ì œì•ˆë°›ê¸°")
    
    st.markdown("---")
    st.info("""
    **ì‚¬ìš© ë°©ë²•:**
    1. ë¶„ì„í•  ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
    2. ë°ì´í„°ê°€ í‘œì‹œë˜ë©´, ì±„íŒ…ì°½ì— ì›í•˜ëŠ” ë¶„ì„ ì‘ì—…ì„ í•œê¸€ë¡œ ì…ë ¥í•©ë‹ˆë‹¤. (ì˜ˆ: 'ë°ì´í„° ì²˜ìŒ 5ì¤„ ë³´ì—¬ì¤˜')
    3. ìƒì„±ëœ ì½”ë“œë¥¼ ë³µì‚¬í•˜ì—¬ ì‹¤ì œ ì•±ì— ì ìš©í•´ë³´ì„¸ìš”!
    """)

# íŒŒì¼ì´ ì—…ë¡œë“œ ë˜ì—ˆì„ ë•Œì˜ ë¡œì§
if uploaded_file is not None:
    df = load_data(uploaded_file)
    
    if df is not None:
        st.header("ğŸ“„ ì—…ë¡œë“œëœ ë°ì´í„° ì •ë³´")
        with st.expander("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5ê°œ í–‰)"):
            st.dataframe(df.head())
        
        # ë°ì´í„°í”„ë ˆì„ì˜ ê¸°ë³¸ ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì •ë¦¬ (Geminiì—ê²Œ ì „ë‹¬í•  ì •ë³´)
        df_info = f"""
        - íŒŒì¼ëª…: {uploaded_file.name}
        - í–‰ì˜ ìˆ˜: {df.shape[0]}
        - ì—´ì˜ ìˆ˜: {df.shape[1]}
        - ì»¬ëŸ¼ëª…: {df.columns.tolist()}
        - ë°ì´í„° íƒ€ì…: \n{df.dtypes.to_string()}
        """
        st.text_area("ë°ì´í„° ìš”ì•½ ì •ë³´ (AI ì°¸ì¡°ìš©)", df_info, height=200)

        st.markdown("---")
        st.header("ğŸ’¬ ì±„íŒ…ìœ¼ë¡œ ì½”ë“œ ìƒì„±í•˜ê¸°")

        # ì±„íŒ… ê¸°ë¡ì„ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if "messages" not in st.session_state:
            st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–¤ ë¶„ì„ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"}]

        # ì´ì „ ì±„íŒ… ê¸°ë¡ í‘œì‹œ
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # ì‚¬ìš©ì ì…ë ¥
        if prompt := st.chat_input("ì˜ˆ: 'ê²°ì¸¡ì¹˜ê°€ ì–¼ë§ˆë‚˜ ìˆëŠ”ì§€ ì•Œë ¤ì¤˜'"):
            if not GEMINI_API_AVAILABLE:
                st.error("Gemini APIê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•„ ì±„íŒ…ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ì‚¬ìš©ì ë©”ì‹œì§€ ê¸°ë¡ ë° í‘œì‹œ
                st.session_state.messages.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.markdown(prompt)

                # AI ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
                with st.chat_message("assistant"):
                    with st.spinner("AIê°€ ì½”ë“œë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                        response_stream = get_gemini_response(prompt, df_info)
                        
                        full_response = ""
                        response_placeholder = st.empty()
                        for chunk in response_stream:
                            # ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ ì½”ë“œ ë¸”ë¡ ë§ˆì»¤ ì œê±°
                            clean_chunk = chunk.text.replace("```python", "").replace("```", "")
                            full_response += clean_chunk
                            response_placeholder.code(full_response, language="python")
                        
                        # ì™„ì„±ëœ ì½”ë“œ ë¸”ë¡ í‘œì‹œ
                        response_placeholder.code(full_response, language="python")
                
                # AI ì‘ë‹µ ê¸°ë¡
                st.session_state.messages.append({"role": "assistant", "content": full_response})

                # êµìœ¡ì  ê¸°ëŠ¥: ì½”ë“œ ì„¤ëª…
                if explain_code and full_response:
                    with st.expander("ì½”ë“œ ì„¤ëª… ë³´ê¸° ğŸ”"):
                        with st.spinner("AIê°€ ì½”ë“œë¥¼ ì„¤ëª…í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                            explain_prompt = f"ë‹¤ìŒ Python ì½”ë“œê°€ ì–´ë–¤ ì—­í• ì„ í•˜ëŠ”ì§€ ê° ì¤„ë³„ë¡œ ì´ˆë³´ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì¤˜:\n\n```python\n{full_response}\n```"
                            explain_response = get_gemini_response(explain_prompt, df_info)
                            st.write_stream(explain_response)
                
                # êµìœ¡ì  ê¸°ëŠ¥: ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ
                if suggest_next and full_response:
                    with st.expander("ë‹¤ìŒ ë¶„ì„ ë‹¨ê³„ ì¶”ì²œ ğŸ’¡"):
                         with st.spinner("AIê°€ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì œì•ˆí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                            suggestion_prompt = f"ë°©ê¸ˆ '{prompt}' ìš”ì²­ì— ë”°ë¼ ì½”ë“œë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ì´ ë¶„ì„ì— ì´ì–´ ì‹œë„í•´ë³¼ ë§Œí•œ í¥ë¯¸ë¡œìš´ ë‹¤ìŒ ë°ì´í„° ë¶„ì„ ì§ˆë¬¸ 3ê°€ì§€ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”. ì§ˆë¬¸ë§Œ ê°„ê²°í•˜ê²Œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³´ì—¬ì£¼ì„¸ìš”."
                            suggestion_response = get_gemini_response(suggestion_prompt, df_info)
                            st.write_stream(suggestion_response)

else:
    st.info("ë°ì´í„° ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´ ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
