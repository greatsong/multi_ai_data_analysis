import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from io import StringIO, BytesIO
import json
import base64
from datetime import datetime
import chardet
import time
import re

# OpenAI
try:
    from openai import OpenAI
except ImportError:
    OpenAI = None

# Google Gemini
try:
    import google.generativeai as genai
except ImportError:
    genai = None

# Anthropic Claude
try:
    from anthropic import Anthropic
except ImportError:
    Anthropic = None

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë°ì´í„° ë¶„ì„ êµìœ¡ ë„ìš°ë¯¸",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'df' not in st.session_state:
    st.session_state.df = None
if 'df_processed' not in st.session_state:
    st.session_state.df_processed = None
if 'generated_codes' not in st.session_state:
    st.session_state.generated_codes = []
if 'conversation_context' not in st.session_state:
    st.session_state.conversation_context = []

# AI ëª¨ë¸ ì„¤ì •
def get_ai_response(prompt, api_key, model_type, model_name, system_prompt=""):
    try:
        if not api_key:
            return "API í‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
            
        if model_type == "OpenAI" and OpenAI:
            try:
                client = OpenAI(api_key=api_key)
                messages = [{"role": "system", "content": system_prompt}] if system_prompt else []
                messages.append({"role": "user", "content": prompt})
                
                response = client.chat.completions.create(
                    model=model_name,
                    messages=messages,
                    temperature=0.7,
                    timeout=30
                )
                return response.choices[0].message.content
            except Exception as e:
                if "api_key" in str(e).lower():
                    return "OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                return f"OpenAI ì˜¤ë¥˜: {str(e)}"
            
        elif model_type == "Gemini" and genai:
            try:
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel(model_name)
                full_prompt = f"{system_prompt}\n\n{prompt}" if system_prompt else prompt
                response = model.generate_content(full_prompt)
                return response.text
            except Exception as e:
                if "api_key" in str(e).lower():
                    return "Gemini API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                return f"Gemini ì˜¤ë¥˜: {str(e)}"
            
        elif model_type == "Claude" and Anthropic:
            try:
                client = Anthropic(api_key=api_key)
                full_prompt = f"{system_prompt}\n\n{prompt}" if system_prompt else prompt
                response = client.messages.create(
                    model=model_name,
                    max_tokens=4000,
                    messages=[{"role": "user", "content": full_prompt}],
                    timeout=30
                )
                return response.content[0].text
            except Exception as e:
                if "api_key" in str(e).lower():
                    return "Claude API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                return f"Claude ì˜¤ë¥˜: {str(e)}"
            
    except Exception as e:
        return f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    return f"{model_type}ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

# ë°ì´í„° ë¶„ì„ í•¨ìˆ˜
def analyze_data(df):
    analysis = {
        "shape": df.shape,
        "columns": list(df.columns),
        "dtypes": df.dtypes.to_dict(),
        "missing_values": df.isnull().sum().to_dict(),
        "numeric_summary": df.describe().to_dict() if len(df.select_dtypes(include=[np.number]).columns) > 0 else {},
        "sample_data": df.head(5).to_dict(),
        "unique_counts": {col: df[col].nunique() for col in df.columns}
    }
    return analysis

# íŒŒì¼ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜
def get_download_link(df, filename, file_format='csv', encoding='utf-8-sig'):
    if file_format == 'csv':
        csv = df.to_csv(index=False, encoding=encoding)
        b64 = base64.b64encode(csv.encode(encoding)).decode()
        mime = 'text/csv'
    else:  # excel
        output = BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            df.to_excel(writer, index=False)
        b64 = base64.b64encode(output.getvalue()).decode()
        mime = 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    
    href = f'<a href="data:{mime};base64,{b64}" download="{filename}">ğŸ“¥ {filename} ë‹¤ìš´ë¡œë“œ</a>'
    return href

# ì½”ë“œ ì¶”ì¶œ í•¨ìˆ˜
def extract_code_from_response(response):
    # ì½”ë“œ ë¸”ë¡ ì°¾ê¸°
    code_blocks = re.findall(r'```python\n(.*?)\n```', response, re.DOTALL)
    if not code_blocks:
        code_blocks = re.findall(r'```\n(.*?)\n```', response, re.DOTALL)
    return code_blocks

# ë©”ì¸ ì•±
st.title("ğŸ“ ë°ì´í„° ë¶„ì„ êµìœ¡ ë„ìš°ë¯¸")
st.markdown("### AIì™€ í•¨ê»˜ ë°ì´í„°ë¥¼ íƒìƒ‰í•˜ê³  ë¶„ì„í•´ë³´ì„¸ìš”!")

# ì‚¬ì´ë“œë°” - AI ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ AI ì„¤ì •")
    
    # AI ëª¨ë¸ ì„ íƒ
    model_type = st.selectbox(
        "AI ëª¨ë¸ ì„ íƒ",
        ["OpenAI", "Gemini", "Claude"]
    )
    
    # ëª¨ë¸ë³„ ì„¸ë¶€ ì˜µì…˜
    if model_type == "OpenAI":
        model_options = ["gpt-4o-mini", "gpt-4o", "gpt-4-turbo", "gpt-3.5-turbo"]
    elif model_type == "Gemini":
        model_options = ["gemini-1.5-flash", "gemini-1.5-pro", "gemini-1.0-pro"]
    else:  # Claude
        model_options = ["claude-3-5-sonnet-20241022", "claude-3-opus-20240229", "claude-3-haiku-20240307"]
    
    model_name = st.selectbox("ëª¨ë¸ ë²„ì „", model_options)
    
    # API í‚¤ ì…ë ¥
    api_key = st.text_input(
        f"{model_type} API í‚¤",
        type="password",
        placeholder="API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
    )
    
    # ê¸°ë³¸ API í‚¤ ì„¤ì •
    if not api_key:
        try:
            if model_type == "OpenAI":
                api_key = st.secrets.get("openai_api_key", "")
            elif model_type == "Gemini":
                api_key = st.secrets.get("gemini_api_key", "")
            else:
                api_key = st.secrets.get("claude_api_key", "")
            
            if api_key:
                st.success("âœ… ê¸°ë³¸ API í‚¤ ë¡œë“œë¨")
        except:
            st.info("ğŸ’¡ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
    
    st.divider()
    
    # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.session_state.conversation_context = []
        st.session_state.generated_codes = []
        st.rerun()
    
    st.divider()
    
    # requirements.txt ìƒì„±
    if st.button("ğŸ“‹ requirements.txt ìƒì„±"):
        requirements = """streamlit
pandas
numpy
plotly
openpyxl
xlsxwriter
openai
google-generativeai
anthropic
chardet"""
        st.code(requirements, language="text")

# ë©”ì¸ ì»¨í…ì¸ 
col1, col2 = st.columns([1, 2])

# ì™¼ìª½: ë°ì´í„° ì—…ë¡œë“œ
with col1:
    st.header("ğŸ“¤ ë°ì´í„° ì—…ë¡œë“œ")
    
    uploaded_file = st.file_uploader(
        "CSV ë˜ëŠ” Excel íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
        type=['csv', 'xlsx', 'xls']
    )
    
    if uploaded_file is not None:
        try:
            # íŒŒì¼ ì½ê¸° with ì¸ì½”ë”© ìë™ ê°ì§€
            if uploaded_file.name.endswith('.csv'):
                encodings = ['utf-8', 'cp949', 'euc-kr', 'latin1']
                df = None
                
                for encoding in encodings:
                    try:
                        uploaded_file.seek(0)
                        df = pd.read_csv(uploaded_file, encoding=encoding)
                        st.success(f"âœ… {encoding} ì¸ì½”ë”©ìœ¼ë¡œ ì½ê¸° ì„±ê³µ")
                        break
                    except:
                        continue
                
                if df is None:
                    uploaded_file.seek(0)
                    raw_data = uploaded_file.read()
                    detected = chardet.detect(raw_data)
                    st.error(f"ì¸ì½”ë”© ìë™ ê°ì§€ ì‹¤íŒ¨ (ê°ì§€: {detected['encoding']})")
            else:
                df = pd.read_excel(uploaded_file)
                st.success("âœ… Excel íŒŒì¼ ì½ê¸° ì„±ê³µ")
            
            if df is not None:
                st.session_state.df = df
                
                # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                st.subheader("ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
                st.dataframe(df.head(5), height=200)
                
                # ê¸°ë³¸ ì •ë³´
                analysis = analyze_data(df)
                st.metric("í–‰ ìˆ˜", analysis['shape'][0])
                st.metric("ì—´ ìˆ˜", analysis['shape'][1])
                
                # ì²« ì—…ë¡œë“œ ì‹œ ìë™ ë¶„ì„ ë©”ì‹œì§€ ì¶”ê°€
                if len(st.session_state.messages) == 0:
                    intro_message = f"""ë°ì´í„°ê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤! 

ğŸ“Š **ë°ì´í„° ê°œìš”:**
- í¬ê¸°: {analysis['shape'][0]}í–‰ Ã— {analysis['shape'][1]}ì—´
- ì—´: {', '.join(analysis['columns'][:5])}{'...' if len(analysis['columns']) > 5 else ''}

ì–´ë–¤ ë¶„ì„ì„ í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? ì˜ˆë¥¼ ë“¤ì–´:
- "ì´ ë°ì´í„°ì˜ íŠ¹ì„±ì„ ë¶„ì„í•´ì¤˜"
- "ì‹œê°„ëŒ€ë³„ ì¶”ì´ë¥¼ ë³´ê³  ì‹¶ì–´"
- "ì¹´í…Œê³ ë¦¬ë³„ ë¹„êµ ê·¸ë˜í”„ë¥¼ ë§Œë“¤ì–´ì¤˜"
- "ì´ìƒì¹˜ë¥¼ ì°¾ì•„ì„œ ì²˜ë¦¬í•˜ê³  ì‹¶ì–´"

ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”! ì œê°€ ì ì ˆí•œ ì½”ë“œë¥¼ ë§Œë“¤ì–´ë“œë¦´ê²Œìš”. ğŸ˜Š"""
                    
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": intro_message
                    })
                
        except Exception as e:
            st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
    
    # ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì„¹ì…˜
    if st.session_state.df_processed is not None:
        st.divider()
        st.subheader("ğŸ“¥ ì²˜ë¦¬ëœ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
        
        file_format = st.selectbox("í˜•ì‹", ["CSV", "Excel"], key="download_format")
        
        if file_format == "CSV":
            encoding_option = st.selectbox(
                "ì¸ì½”ë”©", 
                ["utf-8-sig (ê¶Œì¥)", "cp949", "euc-kr"],
                key="download_encoding"
            )
            encoding_map = {
                "utf-8-sig (ê¶Œì¥)": "utf-8-sig",
                "cp949": "cp949",
                "euc-kr": "euc-kr"
            }
            selected_encoding = encoding_map[encoding_option]
            
            st.markdown(
                get_download_link(
                    st.session_state.df_processed, 
                    "processed_data.csv", 
                    "csv", 
                    selected_encoding
                ), 
                unsafe_allow_html=True
            )
        else:
            st.markdown(
                get_download_link(
                    st.session_state.df_processed, 
                    "processed_data.xlsx", 
                    "excel"
                ), 
                unsafe_allow_html=True
            )

# ì˜¤ë¥¸ìª½: AI ëŒ€í™”
with col2:
    st.header("ğŸ’¬ AIì™€ ë°ì´í„° ë¶„ì„ ëŒ€í™”")
    
    # ëŒ€í™” ë‚´ì—­ í‘œì‹œ
    chat_container = st.container()
    with chat_container:
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.write(message["content"])
                
                # ì½”ë“œê°€ í¬í•¨ëœ ê²½ìš° ì‹¤í–‰ ë²„íŠ¼ ì¶”ê°€
                if message["role"] == "assistant" and "```python" in message["content"]:
                    code_blocks = extract_code_from_response(message["content"])
                    for idx, code in enumerate(code_blocks):
                        col_run, col_copy = st.columns([1, 1])
                        with col_run:
                            if st.button(f"â–¶ï¸ ì½”ë“œ ì‹¤í–‰", key=f"run_{len(st.session_state.messages)}_{idx}"):
                                try:
                                    # ì•ˆì „í•œ ì‹¤í–‰ í™˜ê²½
                                    exec_globals = {
                                        'st': st,
                                        'pd': pd,
                                        'np': np,
                                        'px': px,
                                        'go': go,
                                        'df': st.session_state.df,
                                        'df_processed': st.session_state.df_processed
                                    }
                                    
                                    # ì‹¤í–‰ ê²°ê³¼ë¥¼ ìº¡ì²˜í•˜ê¸° ìœ„í•œ ì»¨í…Œì´ë„ˆ
                                    with st.expander("ì‹¤í–‰ ê²°ê³¼", expanded=True):
                                        exec(code, exec_globals, exec_globals)
                                        
                                        # df_processedê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆëŠ”ì§€ í™•ì¸
                                        if 'df_processed' in exec_globals and exec_globals['df_processed'] is not None:
                                            st.session_state.df_processed = exec_globals['df_processed']
                                            
                                except Exception as e:
                                    st.error(f"ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
                        
                        with col_copy:
                            if st.button(f"ğŸ“‹ ë³µì‚¬", key=f"copy_{len(st.session_state.messages)}_{idx}"):
                                st.code(code, language="python")
                                st.info("ìœ„ ì½”ë“œë¥¼ ë³µì‚¬í•˜ì„¸ìš”!")
    
    # ì‚¬ìš©ì ì…ë ¥
    user_input = st.chat_input("ë°ì´í„°ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ììœ ë¡­ê²Œ ë¬¼ì–´ë³´ì„¸ìš”!")
    
    if user_input:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": user_input})
        
        # AI ì‘ë‹µ ìƒì„±
        if st.session_state.df is not None:
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            system_prompt = """ë‹¹ì‹ ì€ ì¹œì ˆí•œ ë°ì´í„° ë¶„ì„ êµìœ¡ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ë©° ë°ì´í„° ë¶„ì„ì„ ë„ì™€ì£¼ì„¸ìš”.

ì¤‘ìš” ê·œì¹™:
1. ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ íŒŒì•…í•˜ì—¬ ì ì ˆí•œ ë¶„ì„ ë°©ë²•ê³¼ ì‹œê°í™”ë¥¼ ì œì•ˆí•˜ì„¸ìš”
2. ì½”ë“œê°€ í•„ìš”í•œ ê²½ìš°, ìì—°ìŠ¤ëŸ½ê²Œ "ì´ëŸ° ì½”ë“œë¥¼ ë§Œë“¤ì–´ë“œë¦´ê¹Œìš”?"ë¼ê³  ë¬¼ì–´ë³´ì„¸ìš”
3. ì½”ë“œë¥¼ ìƒì„±í•  ë•ŒëŠ” ë°˜ë“œì‹œ ```python ì½”ë“œë¸”ë¡ ``` í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”
4. í•œê¸€ ì£¼ì„ìœ¼ë¡œ ì½”ë“œë¥¼ ì„¤ëª…í•˜ì„¸ìš”
5. plotlyë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸í„°ë™í‹°ë¸Œí•œ ì‹œê°í™”ë¥¼ ë§Œë“œì„¸ìš”
6. ì‹¤í–‰ ê°€ëŠ¥í•œ ì™„ì „í•œ ì½”ë“œë¥¼ ì œê³µí•˜ì„¸ìš”
7. dfëŠ” ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìœ¼ë¯€ë¡œ dfë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì„¸ìš”
8. ì „ì²˜ë¦¬ëœ ë°ì´í„°ëŠ” df_processedë¡œ ì €ì¥í•˜ì„¸ìš”"""

            # ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            analysis = analyze_data(st.session_state.df)
            data_context = f"""
í˜„ì¬ ë°ì´í„° ì •ë³´:
- í¬ê¸°: {analysis['shape']}
- ì—´: {list(analysis['columns'])}
- ë°ì´í„° íƒ€ì…: {analysis['dtypes']}
- ê²°ì¸¡ê°’: {analysis['missing_values']}
- ê³ ìœ ê°’ ê°œìˆ˜: {analysis['unique_counts']}
"""

            # ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨
            conversation_history = "\n".join([
                f"{msg['role']}: {msg['content'][:200]}..." 
                for msg in st.session_state.messages[-5:]  # ìµœê·¼ 5ê°œ ëŒ€í™”
            ])

            # ì „ì²´ í”„ë¡¬í”„íŠ¸
            full_prompt = f"""
{data_context}

ìµœê·¼ ëŒ€í™” ë‚´ìš©:
{conversation_history}

ì‚¬ìš©ì ì§ˆë¬¸: {user_input}

ìœ„ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê³  ë„ì›€ì´ ë˜ëŠ” ì‘ë‹µì„ í•´ì£¼ì„¸ìš”.
í•„ìš”ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œë¥¼ ì œì•ˆí•˜ì„¸ìš”."""

            # AI ì‘ë‹µ ë°›ê¸°
            with st.spinner("ìƒê° ì¤‘..."):
                response = get_ai_response(
                    full_prompt, 
                    api_key, 
                    model_type, 
                    model_name,
                    system_prompt
                )
            
            # ì‘ë‹µ ì¶”ê°€
            st.session_state.messages.append({"role": "assistant", "content": response})
            
        else:
            # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
            st.session_state.messages.append({
                "role": "assistant", 
                "content": "ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”! ì™¼ìª½ì—ì„œ CSVë‚˜ Excel íŒŒì¼ì„ ì„ íƒí•˜ì‹¤ ìˆ˜ ìˆì–´ìš”. ğŸ“Š"
            })
        
        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
        st.rerun()

# í•˜ë‹¨ ì •ë³´
st.divider()
with st.expander("ğŸ’¡ ì‚¬ìš© íŒ", expanded=False):
    st.markdown("""
    ### ì´ëŸ° ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”:
    - "ì´ ë°ì´í„°ì˜ ì „ì²´ì ì¸ íŠ¹ì„±ì„ ë¶„ì„í•´ì¤˜"
    - "Aì—´ê³¼ Bì—´ì˜ ìƒê´€ê´€ê³„ë¥¼ ë³´ì—¬ì¤˜"
    - "ì‹œê°„ëŒ€ë³„ ë³€í™” ì¶”ì´ë¥¼ ê·¸ë˜í”„ë¡œ ê·¸ë ¤ì¤˜"
    - "ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”í•´ì„œ í‰ê· ì„ ê³„ì‚°í•´ì¤˜"
    - "ì´ìƒì¹˜ë¥¼ ì°¾ì•„ì„œ ì œê±°í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì¤˜"
    - "ë¨¸ì‹ ëŸ¬ë‹ì„ ìœ„í•œ ì „ì²˜ë¦¬ ë°©ë²•ì„ ì œì•ˆí•´ì¤˜"
    
    ### ì½”ë“œ ì‹¤í–‰:
    - AIê°€ ìƒì„±í•œ ì½”ë“œëŠ” ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
    - ì‹¤í–‰ ê²°ê³¼ëŠ” ë°”ë¡œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤
    - ì²˜ë¦¬ëœ ë°ì´í„°ëŠ” ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
    """)

# ìƒì„±ëœ ì½”ë“œ ëª¨ìŒ (ì‚¬ì´ë“œë°” í•˜ë‹¨)
with st.sidebar:
    if len(st.session_state.generated_codes) > 0:
        st.divider()
        st.header("ğŸ“ ìƒì„±ëœ ì½”ë“œ ëª¨ìŒ")
        for idx, code_info in enumerate(st.session_state.generated_codes):
            with st.expander(f"ì½”ë“œ {idx+1}: {code_info['title'][:20]}..."):
                st.code(code_info['code'], language="python")
                if st.button(f"ğŸ“‹ ë³µì‚¬", key=f"sidebar_copy_{idx}"):
                    st.info("ì½”ë“œë¥¼ ë³µì‚¬í•˜ì„¸ìš”!")
